{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SET UP THE ENVIRONMENT ###\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sklearn.model_selection\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LOAD DATA ###\n",
    "\n",
    "DATA_DIR = os.path.join('data')\n",
    "\n",
    "data_paths = {'A': {'data': os.path.join(DATA_DIR, 'A_hhold_train.csv'), \n",
    "                    'pred':  os.path.join(DATA_DIR, 'A_hhold_test.csv')}, \n",
    "              \n",
    "              'B': {'data': os.path.join(DATA_DIR, 'B_hhold_train.csv'), \n",
    "                    'pred':  os.path.join(DATA_DIR, 'B_hhold_test.csv')}, \n",
    "              \n",
    "              'C': {'data': os.path.join(DATA_DIR, 'C_hhold_train.csv'), \n",
    "                    'pred':  os.path.join(DATA_DIR, 'C_hhold_test.csv')}}\n",
    "\n",
    "a_data = pd.read_csv(data_paths['A']['data'], index_col='id')\n",
    "b_data = pd.read_csv(data_paths['B']['data'], index_col='id')\n",
    "c_data = pd.read_csv(data_paths['C']['data'], index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPLORE CLASS DISTRIBUTION ###\n",
    "\n",
    "#a_data.poor.value_counts().plot.bar(title='Number of Poor for country A')\n",
    "#b_data.poor.value_counts().plot.bar(title='Number of Poor for country B')\n",
    "c_data.poor.value_counts().plot.bar(title='Number of Poor for country C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PRE-PROCESSING FUNCTIONS ###\n",
    "\n",
    "# Standardize features\n",
    "def standardize(df, numeric_only=True):\n",
    "    numeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "    \n",
    "    # subtracy mean and divide by std\n",
    "    df[numeric.columns] = (numeric - numeric.mean()) / numeric.std()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def pre_process_data(df, enforce_cols=None):\n",
    "    #print(\"Input shape:\\t{}\".format(df.shape))   \n",
    "\n",
    "    df = standardize(df)\n",
    "    #print(\"After standardization: {}\".format(df.shape))\n",
    "        \n",
    "    # create dummy variables for categoricals\n",
    "    df = pd.get_dummies(df)\n",
    "    #print(\"After converting categoricals:\\t{}\".format(df.shape))\n",
    "    \n",
    "\n",
    "    # match test set and training set columns\n",
    "    if enforce_cols is not None:\n",
    "        to_drop = np.setdiff1d(df.columns, enforce_cols)\n",
    "        to_add = np.setdiff1d(enforce_cols, df.columns)\n",
    "\n",
    "        df.drop(to_drop, axis=1, inplace=True)\n",
    "        df = df.assign(**{c: 0 for c in to_add})\n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PRE-PROCESS DATA FOR TRAINING ###\n",
    "\n",
    "X_data_A = pre_process_data(a_data.drop('poor', axis=1))\n",
    "y_data_A = np.ravel(a_data.poor)\n",
    "\n",
    "X_data_B = pre_process_data(b_data.drop('poor', axis=1))\n",
    "y_data_B = np.ravel(b_data.poor)\n",
    "\n",
    "X_data_C = pre_process_data(c_data.drop('poor', axis=1))\n",
    "y_data_C = np.ravel(c_data.poor)\n",
    "\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = sk.cross_validation.train_test_split( \\\n",
    "                                            X_data_A, y_data_A , test_size=0.25, random_state=0, stratify=y_data_A)\n",
    "\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = sk.cross_validation.train_test_split( \\\n",
    "                                            X_data_B, y_data_B , test_size=0.25, random_state=0, stratify=y_data_B)\n",
    "\n",
    "X_train_C, X_test_C, y_train_C, y_test_C = sk.cross_validation.train_test_split( \\\n",
    "                                            X_data_C, y_data_C , test_size=0.25, random_state=0, stratify=y_data_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CREATE AND TRAIN MODELS ###\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import grid_search\n",
    "\n",
    "def train_model(features, labels, **kwargs):\n",
    "    \n",
    "    # instantiate model\n",
    "    model = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "    \n",
    "    # train model\n",
    "    model.fit(features, labels)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#train all models\n",
    "model_a = train_model(X_train_A, y_train_A)\n",
    "model_b = train_model(X_train_B, y_train_B)\n",
    "model_c = train_model(X_train_C, y_train_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ASSESS MODEL PERFORMANCE ###\n",
    "test_pred_A = model_a.predict_proba(X_test_A)\n",
    "test_pred_B = model_b.predict_proba(X_test_B)\n",
    "test_pred_C = model_c.predict_proba(X_test_C)\n",
    "\n",
    "y_test_all = np.hstack((y_test_A, y_test_B, y_test_C))\n",
    "test_pred_all = np.hstack((test_pred_A[:, 1], test_pred_B[:, 1], test_pred_C[:, 1]))\n",
    "\n",
    "perf_a = sk.metrics.log_loss(y_test_A, test_pred_A)\n",
    "perf_b = sk.metrics.log_loss(y_test_B, test_pred_B)\n",
    "perf_c = sk.metrics.log_loss(y_test_C, test_pred_C)\n",
    "\n",
    "perf_all = sk.metrics.log_loss(y_test_all, test_pred_all)\n",
    "\n",
    "roc_auc_all = sk.metrics.roc_auc_score(y_test_all, test_pred_all)\n",
    "\n",
    "print (\"model A logloss: \", perf_a)\n",
    "print (\"model B logloss: \", perf_b)\n",
    "print (\"model C logloss: \", perf_c)\n",
    "print (\"overall logloss: \", perf_all)\n",
    "\n",
    "print (\"overall AUC-ROC: \", roc_auc_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### MAKE PREDICTIONS ###\n",
    "\n",
    "# load test data\n",
    "a_test = pd.read_csv(data_paths['A']['pred'], index_col='id')\n",
    "b_test = pd.read_csv(data_paths['B']['pred'], index_col='id')\n",
    "c_test = pd.read_csv(data_paths['C']['pred'], index_col='id')\n",
    "\n",
    "# pre-process test data\n",
    "a_test = pre_process_data(a_test, enforce_cols=X_data_A.columns)\n",
    "b_test = pre_process_data(b_test, enforce_cols=X_data_B.columns)\n",
    "c_test = pre_process_data(c_test, enforce_cols=X_data_C.columns)\n",
    "\n",
    "# make predictions for test datae\n",
    "a_preds = model_a.predict_proba(a_test)\n",
    "b_preds = model_b.predict_proba(b_test)\n",
    "c_preds = model_c.predict_proba(c_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CREATE A SUBMISSION ###\n",
    "\n",
    "def make_country_sub(preds, test_feat, country):\n",
    "    # make sure we code the country correctly\n",
    "    country_codes = ['A', 'B', 'C']\n",
    "    \n",
    "    # get just the poor probabilities\n",
    "    country_sub = pd.DataFrame(data=preds[:, 1],  # proba p=1\n",
    "                               columns=['poor'], \n",
    "                               index=test_feat.index)\n",
    "\n",
    "    \n",
    "    # add the country code for joining later\n",
    "    country_sub[\"country\"] = country\n",
    "    return country_sub[[\"country\", \"poor\"]]\n",
    "\n",
    "# convert preds to data frames\n",
    "a_sub = make_country_sub(a_preds, a_test, 'A')\n",
    "b_sub = make_country_sub(b_preds, b_test, 'B')\n",
    "c_sub = make_country_sub(c_preds, c_test, 'C')\n",
    "\n",
    "submission = pd.concat([a_sub, b_sub, c_sub])\n",
    "submission.head()\n",
    "submission.to_csv('submission-take-one.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
